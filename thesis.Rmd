---
title: "Assessing Phosphorus Sources with Synoptic Sampling in the Surface Waters of a Mixed-Use, Montane Watershed"
author: "Austin W. Pearce"
date: "Documentation last updated on July 8, 2017"
output: 
  html_document: 
    theme: journal
---
# Intro

I consider myself new to R. I haven't even been coding for a year. And most of the coding I know is for making simple data visualizations. However, in an effort to better document my thesis data for the next person who might find it, below is some documentation and code for the synoptic sampling data I collected while a master's student at BYU from 2015 - 2017 with Dr. Neil Hansen.

# Setup
Most of the packages required for all code below can be installed in one fell swoop by installing the `tidyverse` package. GIS shapefiles were imported using `rgdal`. The `viridis` package provides pleasing color palettes that are also colorblind friendly. `gridExtra` allows multiple ggplots to be arranged side-by-side.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)

library(tidyverse)
library(magrittr)
library(rgdal)
library(viridis)
library(gridExtra)
```

# The Watershed Map

To effectively orient the reader who views these spatial data, below is code to produce a basemap of the Wallsburg watershed. This basemap is simplified to only include the watershed boundary and the three major tributaries. Values for *Latitude* and *Longitude* are not included on the axis to maintain simplicity, and because the coordinates of the sites do not really matter in the context of this study.

*Note: streams were read in as separate shapefiles because I had issues plotting when all streams were in one shapefile.*

```{r build map, include=FALSE}
# Shapefiles are in WGS 84 lat-long projection
# Main Creek (mc), Spring Creek (sc), and so on
bound = readOGR('input/shapefiles', 'boundary')
mc    = readOGR('input/shapefiles', 'maincreek')
sc    = readOGR('input/shapefiles', 'springcreek')
lhc   = readOGR('input/shapefiles', 'littlehobble')
lhclf = readOGR('input/shapefiles', 'littlehobble2')

# build ggplot object for outline of watershed
bound = geom_polygon(data = bound, aes(x = long, y = lat),
                      col = "gray50", fill = NA)

# build ggplot objects for the streams
sc    = geom_path(data = sc,    aes(long, lat), col = "gray50")
mc    = geom_path(data = mc,    aes(long, lat), col = "gray50")
lhc   = geom_path(data = lhc,   aes(long, lat), col = "gray50")
lhclf = geom_path(data = lhclf, aes(long, lat), col = "gray50")

# A ggplot basemap of Wallsburg watershed with streams
map.wallsburg = ggplot() +
  bound +
  sc + mc + lhc + lhclf +
  coord_quickmap() + 
  labs(x = "Longitude",
       y = "Latitude") +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(size = 10),
        panel.grid = element_blank(),
        legend.text = element_text(size = 10),
        strip.text = element_text(size = 10),
        legend.position = 'top')

#remove other objects in order to maintain neat R environment
remove(bound, lhc, lhclf, mc, sc)

# Save as RDS for quicker loading next time.
write_rds(map.wallsburg, path = 'input/wallsburg_map.rds')
```

If the user wants, the previous code can be skipped once the RDS file is created. In this way, the user can skip reading and plotting the shapefiles each time the notebook is run. But it's optional given that the user may want to reproduce the map each time to ensure accuracy in the code.

```{r display map, echo=FALSE, fig.width=4, fig.height=5}
map.wallsburg = readRDS('input/wallsburg_map.rds')
map.wallsburg
```

# Historic Discharge at Outlet
The historical data on the discharge of the Wallsburg Watershed shows clearly the annual flux of water from snowmelt, and helped to determine the sampling dates. Below is the code to generate that plot.

```{r historic annual hydrograph, include = FALSE}
# Get data
# separate data for month averaging
outlet = read_csv('input/outlet.csv') %>% 
  dplyr::filter(. , TP < 1)

outlet_dates = separate(outlet, DATE, c("Y", "M", "D"))

# not necessary but helpful 
outlet_dates$LITERS = outlet_dates$CFS*28.3168 # convert cfs to L/s

#reorder month names from alphabetic
month = factor(outlet_dates$M, levels = month.name)
```

```{r median flow annual, echo=FALSE}
# median flows for each month from 1984 - 2014
flow.med = aggregate(LITERS ~ M, data = outlet_dates, median)

flow.median = ggplot(data = flow.med) +
  geom_area(aes(x = as.integer(M), LITERS), fill = "#00002255") +
  geom_point(aes(x = as.integer(M), LITERS),
             size = 2, pch = 15, col = "#002255") +
  scale_x_continuous(breaks = seq(01, 12, 01)) +
  scale_y_continuous(breaks = seq(0, 2000, 200)) +
  labs(x = "Month Number", y = "Median Discharge (L / s)",
       title = "Historic Discharge at Outlet of Wallsburg Watershed",
       subtitle = 'Median Monthly Discharge for 30 Years: 1984 - 2014') +
  theme_classic() +
  theme(axis.text = element_text(size = 12))

flow.median
```


Some looking at this might note that the volume of water is relatively little; this is a stream in the western United States, after all, a semi-arid region.

# Streamflow
The streamflow data for this analysis can be found in two CSV files. The `master.csv` file contains the streamflow data as measured in the seven sampling campaigns. The `flowmeans.csv` contains the data as averaged between the two years, such that the *Peak* streamflow value for MC01, for example, is the average streamflow at MC01 based on the measurement from May 2015 and May 2016. In a way, this averaging helps to smooth out year-to-year variability and simplify analysis. More on data collection can be read in the thesis document `thesis.pdf`.

```{r flow data, include=FALSE, message=FALSE, warning=FALSE}
# All streamflow (flow) data
flow = read_csv("input/master.csv", na = 'no_access') %>%
  filter(., site != 'MC04') %>%
  select(., id:ls,-cfs) %>%
  drop_na(.)

# streamflow data simplified into the three hydrologic periods:
# 'Rise', 'Peak', & 'Base'
flow_means = read_csv("input/flowmeans.csv")

# This variable reorders the three hydrologic periods into a chronological
# order in terms of the annual hydrograph of the watershed
flow_means$hydros = factor(flow_means$hydro,
                           levels = c('Rise', 'Peak', 'Base'))

# the next data frame provides only the dry sites, which is important to show
# during the baseflow 2015 campaign
flow_dry = filter(flow, ls == 0)

flow_201507 = filter(flow, date == '2015-07-29')
```

As described in the thesis section on traditional synoptic sampling approach, the baseflow sampling campaign on 2015 provided certain insights into the P loading patterns of the watershed. The streamflows are as follows in the plot below, starting with the baseflow streamflow of 2015 and then the streamflows in each of the averaged hydrologic periods.

```{r baseflow 2015, echo=FALSE, fig.width=4, fig.height=5}

# Baseflow 2015
plt.flow201507 = map.wallsburg +
  geom_point(data = flow_201507,
             aes(x = long, y = lat, size = ls), # fill inside of point
             pch = 16, alpha = 0.1, col = '#002255') +
  geom_point(data = flow_201507,
             aes(x = long, y = lat, size = ls),
             col = '#002255', pch = 21) +
  geom_point(data = flow_dry,
             aes(x = long, y = lat, shape = as.factor(ls)),
             size = 2) +
  scale_size_area(name = 'Flow\n(L/s)', max_size = 12) +
  scale_shape_discrete(name = '', labels = c('Dry'))

plt.flow201507
```


```{r flow over time, echo=FALSE}

# bubble plot for each sampling campaign
plt.flow = map.wallsburg +
  geom_point(data = flow_means,
             aes(x = long, y = lat, size = ls), # fill
             pch = 16, alpha = 0.1, col = "#002255") +
  geom_point(data = flow_means,
             aes(x = long, y = lat, size = ls),
             col = '#002255', pch = 21) +
  facet_wrap(~ hydros,
             labeller = labeller(.multi_line = FALSE)) +
  scale_size_area(breaks = c(0, 50, 100, 200, 300),
                  max_size = 12, name = "Flow\n(L/s)") +
  scale_shape_discrete(name = '',
                       labels = c('No Access'))
plt.flow
```

# Concentrations
The concentration data for this analysis can be found in two CSV files. The `master.csv` file contains the concentration data as measured in the seven sampling campaigns. The `concmeans.csv` contains the data as averaged between the two years, such that the *Peak* concentration value for MC01, for example, is the average concentration at MC01 based on the measurement from May 2015 and May 2016. In a way, this averaging helps to smooth out year-to-year variability and simplify analysis. More on data collection can be read in the thesis document `thesis.pdf`.

```{r concentration data, include=FALSE}
conc = read_csv('input/master.csv', na = c('dry', 'no_access', 'lost')) %>%
  filter(., site != 'MC04') %>%
  select(., id:dop,-cfs,-ls) %>%
  gather(., 'fraction', 'conc', 10:14) %>%
  drop_na(.)

conc_mean = read_csv('input/concmeans.csv', na = 'dry') %>%
  filter(., site != 'MC04') %>%
  gather(., 'fraction', 'conc', 8:12) %>%
  drop_na(.)

conc_mean_dry = read_csv('input/concmeans.csv') %>%
  filter(., site != 'MC04') %>%
  gather(., 'fraction', 'conc', 8:12) %>%
  dplyr::filter(., conc == 'dry')

# Create variable that helps reorder P Fractions
conc_mean$fractions = factor(conc_mean$fraction,
                              levels = c('TP','PP','TDP','DRP','DOP'))
conc_mean$hydros = factor(conc_mean$hydro,
                           levels = c('Rise', 'Peak', 'Base'))

conc_mean_tp = filter(conc_mean, fraction == 'TP')
```

The concentrations are as follows in the plots below, starting with the baseflow streamflow of 2015, then the concentrations in each of the averaged hydrologic periods, and then the concentrations of each fraction in each hydrologic period.

```{r concentrations, echo=FALSE, message=FALSE}

conc_base = filter(conc, date == '2015-07-29')

conc_base_tp = filter(conc_base, fraction == 'tp')

conc_dry = read_csv('input/concmeans.csv') %>%
  filter(., site != 'MC04') %>%
  gather(., 'fraction', 'conc', 8:12) %>%
  filter(., conc == 'dry')

# TP Only
plt.base_conc = map.wallsburg +
  geom_point(data = conc_base_tp, 
             aes(long, lat, size = conc),
             pch = 21, col = '#002255') +
  geom_point(data = conc_base_tp,
             aes(long, lat, size = conc),
             pch = 16, col = "#002255", alpha = 0.1) +
  geom_point(data = flow_dry,
             aes(x = long, y = lat, shape = as.factor(ls)),
             size = 2) +
  scale_size_area(breaks = c(0, 0.05, 0.1, 0.25),
                  max_size = 10,
                  name = 'Total P\n(mg/L)') +
  scale_shape_discrete(name = '', labels = c('Dry'))

# Export at 480 x 360
plt.base_conc
```

```{r mean TP, echo=FALSE, message=FALSE}
# Mean TP overtime
plt.conc_tp = map.wallsburg +
  geom_point(data = conc_mean_tp, 
             aes(long, lat, size = conc),
             col = '#002255', pch = 21) +
  geom_point(data = conc_mean_tp,
             aes(long, lat, size = conc),
             pch = 16, col = "#002255", alpha = 0.1) +
  scale_size_area(breaks = c(0, 0.05, 0.1, 0.2, 0.3),
                  max_size = 10,
                  name = 'Total P\n(mg/L)') +
  facet_wrap(~ hydros, nrow = 1, labeller = labeller(.multi_line = FALSE))

plt.conc_tp
```

```{r 5P conc, echo=FALSE, message=FALSE, fig.height=8, fig.width=5}
# ggplot for concentration as a function of fraction and date
plt.conc = map.wallsburg +
  geom_point(data = conc_mean,
             aes(long, lat, size = conc),
             col = '#002255', pch = 21) +
  geom_point(data = conc_mean,
             aes(long, lat, size = conc), # fill
             pch = 16, col = "#002255", alpha = 0.1) +
  scale_size_area(breaks = c(0, .01, 0.05, 0.1, 0.2),
                  max_size = 8,
                  name = 'Concentration\n(mg/L)' ) +
  facet_wrap(~ fractions + hydros,
             ncol = 3,
             labeller = labeller(.multi_line = FALSE)) +
  theme(legend.position = 'right')
plt.conc
```

# Loads

```{r load data, echo=FALSE, message=FALSE}
# import data
load = read_csv('input/master_load.csv',
                 na = c('no_access', 'lost')) %>%
  filter(., site != 'MC04') %>%
  select(., id:DOP, -cfs, -ls) %>% 
  gather(., 'fraction', 'load', 10:14)

load_mean = read_csv('input/loadmeans.csv') %>% 
  filter(., site != 'MC04') %>% 
  gather(., 'fraction', 'load', 8:12)

load_mean$fractions = factor(load_mean$fraction,
                              levels = c('TP','PP','TDP','DRP','DOP'))
load_mean$hydros = factor(load_mean$hydro,
                           levels = c('Rise','Peak','Base'))

load_mean_tp = filter(load_mean, fraction == 'TP')

load_base = filter(load, date == '2015-07-29')

load_base_tp = filter(load_base, fraction == 'TP')

load_dry = read_csv('input/master_load.csv') %>%
  filter(., site != 'MC04') %>% 
  select(., id:DOP, -cfs, -ls) %>% 
  gather(., 'fraction', 'load', 10:14) %>% 
  filter(., load == 'no_access' | load == 'lost')
```

The loads at each site are as follows in the plots below, starting with the baseflow streamflow of 2015, then the concentrations in each of the averaged hydrologic periods, and then the concentrations of each fraction in each hydrologic period.

```{r load, echo=FALSE, message=FALSE}
#TP Load at Baseflow in 2015
plt.base_load = map.wallsburg +
  geom_point(data = load_base_tp, 
             aes(long, lat, size = load),
             pch = 21, col = '#002255') +
  geom_point(data = load_base_tp,
             aes(long, lat, size = load),
             pch = 16, col = "#002255", alpha = 0.1) +
  scale_color_discrete(name = 'No Result',
                       labels = 'Dry\nStreambed') +
  scale_size_area(breaks = c(0, 1, 3, 5),
                  max_size = 10,
                  name = 'TP Load\n(mg/s)')

plt.base_load

# TP Loads in each hydrologic period
plt.load_tp = map.wallsburg +
  geom_point(data = load_mean_tp,
             aes(long, lat, size = load),
             pch = 21, col = '#002255') +
  geom_point(data = load_mean_tp,
             aes(long, lat, size = load), # fill
             pch = 16, col = '#002255', alpha = 0.1) +
  scale_size_area(breaks = c(0, 5, 10, 20, 30),
                  max_size = 10,
                  name = "Load\n(mg/s)") +
  facet_wrap(~ hydros,
             ncol = 4,
             labeller = labeller(.multi_line = FALSE))
plt.load_tp
```

```{r loads by fractions, echo=FALSE, fig.height=8, fig.width=5}
# Loads by fraction in each hydrologic period
plt.load = map.wallsburg +
  geom_point(data = load_mean,
             aes(long, lat, size = load),
             pch = 21, col = "#002255") +
  geom_point(data = load_mean,
             aes(long, lat, size = load), # fill
             pch = 16, col = "#002255", alpha = 0.1) +
  scale_size_area(breaks = c(0, 5, 10, 20, 30),
                  max_size = 8,
                  name = "Load\n(mg/s)") +
  facet_wrap(~ fractions + hydros,
             ncol = 3,
             labeller = labeller(.multi_line = FALSE)) +
  theme(legend.position = "right")
plt.load
```

Once more, the results shown spatially as in the baseflow period of 2015.

```{r gridExtra, echo=FALSE, fig.height=8, fig.width=7}
# Put all baseflow 2015 plots together for export
grid.arrange(plt.flow201507, plt.base_conc, plt.base_load, ncol = 2)
```

# Bar Charts

While the map plots shown previously provide insight in to spatial loading patterns, there was a need to focus on the profiles of Main Creek and Spring Creek through bar charts to better understand how P fractions were changing over space, time, and in relation to each other. Remember the abbreviations are such: total P (TP), particulate P (PP), dissolved reactive P (DRP), and dissolved organic P (DOP). Total dissolved P (TDP) is simply the sum of DRP and DOP, and TP is simply the sum of TDP and PP.

```{r barplots, echo=FALSE, message=FALSE, warning=FALSE}
# Barplot for TP loads over time
load_mc_tp = filter(load_mean, stream == 'M') %>% 
  filter(., fraction == 'TP')

bar.mc_tp = ggplot(data = load_mc_tp,
                    aes(x = site, y = load, fill = fractions)) +
  geom_col(position = 'stack') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ hydros,
             ncol = 1,
             scales = 'free') +
  labs(x = 'ID of Site Along Main Creek Profile', y = 'Load (mg/s)') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.mc_tp

load_mc_3frac = filter(load_mean, stream == 'M') %>% 
  filter(., fraction != 'TP' & fraction != 'TDP')

# Bar chart showing Main Creek profile in baseflow 2015
load_mc_base = filter(load_base_tp, stream == 'M')

bar.mc_base = ggplot(data = load_mc_base,
                      aes(x = site, y = load, fill = fraction)) +
  geom_col() +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  labs(x = 'ID of Site Along Main Creek Profile',
       y = 'Load (mg/s)') +
  theme_bw()

bar.mc_base

# Bar chart with sites along x, and loads of free scale on y
# This allows for one to compare the pattern of load increases and decreases
# across various hydrologic periods
bar.mc = ggplot(data = load_mc_3frac,
                        aes(x = site, y = load, fill = fractions)) +
  geom_col(position = 'stack') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ hydros,
             ncol = 1,
             scales = 'free') +
  labs(x = 'ID of Site Along Main Creek Profile',
       y = 'Load (mg/s)') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.mc

# This has the fractions scaled to 100 % (which represents TP)
# In this way, proportions can be compared across sites.
bar.mc_percent = ggplot(data = load_mc_3frac,
                         aes(x = site, y = load, fill = fractions)) +
  geom_col(position = 'fill') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ hydros,
             ncol = 1) +
  labs(x = 'ID of Site Along Main Creek Profile',
       y = 'Percent Composition') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.mc_percent

# For each site, which isn't really necessary if you just look vertically
# on the other graphs
load_mean_3frac = filter(load_mean, fraction != 'TP' & fraction != 'TDP')

bar.sites_percent = ggplot(data = load_mean_3frac,
                    aes(x = hydros, y = load, fill = fractions)) +
  geom_col(position = 'fill') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ site,
             ncol = 4) +
  labs(x = 'Site ID',
       y = 'Load (mg/s)') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.sites_percent
```

The chart `bar.sites_percent` didn't make it into the thesis, but it highlights in a different way some of the insights explained in the thesis document about temporal trends in P loading across the watershed.

Similar charts were made for Spring Creek because Spring Creek was identified as an important contributor to P loads in Main Creek.

```{r spring creek bar, echo=FALSE, message=FALSE, warning=FALSE}
load_sc_3frac = filter(load_mean, stream == 'S') %>% 
  filter(., fraction != 'TP' & fraction != 'TDP')

bar.sc = ggplot(data = load_sc_3frac,
                 aes(x = site, y = load, fill = fractions)) +
  geom_col(position = 'stack') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ hydros,
             ncol = 1,
             scales = 'free') +
  labs(x = 'ID of Site Along Spring Creek Profile',
       y = 'Load (mg/s)') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.sc

bar.sc_percent = ggplot(data = load_sc_3frac,
                             aes(x = site, y = load, fill = fractions)) +
  geom_col(position = 'fill') +
  scale_fill_viridis(name = 'P Fraction', discrete = TRUE) +
  facet_wrap(~ hydros,
             ncol = 1) +
  labs(x = 'ID of Site Along Spring Creek Profile',
       y = 'Percent Composition') +
  theme_bw() +
  theme(strip.text = element_text(size = 12))

bar.sc_percent
```

